# Clasificaci√≥n de Bienestar Psicol√≥gico con MLPClassifier

## Prop√≥sito general

Este script entrena un clasificador MLP (Multi-layer Perceptron) para predecir el estado de bienestar categ√≥rico (`mhc_dx`) a partir de escalas psicol√≥gicas y variables demogr√°ficas/contextuales. Se realiza la divisi√≥n de datos en entrenamiento y prueba, preprocesamiento (escalado), entrenamiento, predicci√≥n y evaluaci√≥n con m√©tricas est√°ndar.

---

## An√°lisis del c√≥digo

1. **Carga de datos:** Se importa el dataset desde un archivo CSV.
2. **Selecci√≥n de caracter√≠sticas y target:** Se eligen 10 variables predictoras relevantes (escalas psicol√≥gicas y datos demogr√°ficos) y la variable objetivo `mhc_dx`.
3. **Divisi√≥n del dataset:** Se separan los datos en conjuntos de entrenamiento (80%) y prueba (20%), con estratificaci√≥n para mantener la distribuci√≥n original de clases.
4. **Preprocesamiento:** Se normalizan las caracter√≠sticas usando `StandardScaler` para que tengan media 0 y desviaci√≥n est√°ndar 1, lo que mejora el desempe√±o del MLP.
5. **Entrenamiento:** Se entrena un modelo `MLPClassifier` con dos capas ocultas de tama√±os 30 y 20, activaci√≥n log√≠stica, regularizaci√≥n (`alpha=0.01`), m√°ximo 3000 iteraciones, y semilla fija para reproducibilidad.
6. **Evaluaci√≥n:** Se predicen las etiquetas en el conjunto de prueba y se calculan m√©tricas de desempe√±o.
7. **Persistencia:** El modelo entrenado se guarda para uso posterior.

---

## An√°lisis de resultados

### Precisi√≥n global

```

Precisi√≥n del modelo: 0.7404

```

- El modelo acert√≥ aproximadamente el 74% de las predicciones en datos no vistos (test).

### Reporte detallado por clase

| Clase | Precision | Recall | F1-score | Soporte |
|-------|-----------|--------|----------|---------|
| 0     | 0.66      | 0.58   | 0.62     | 450     |
| 1     | 0.77      | 0.87   | 0.81     | 1018    |
| 2     | 0.77      | 0.18   | 0.29     | 96      |

- **Clase 0 (Languishing):** El modelo detecta bien la mayor√≠a (recall 0.58), aunque con algunas falsas predicciones (precision 0.66).
- **Clase 1 (Moderado):** Mejor desempe√±o, con alta precisi√≥n y recall, mostrando buena capacidad para identificar correctamente esta clase mayoritaria.
- **Clase 2 (Floreciente):** Precision alta (0.77) pero recall muy bajo (0.18), indica que el modelo es conservador en predecir esta clase y a menudo no detecta muchos casos reales de clase 2.

### Matriz de confusi√≥n

```

[[259 191   0]
[131 882   5]
[  1  78  17]]

```

- Hay confusi√≥n considerable entre la clase 0 y 1, con falsos negativos y positivos.
- La clase 2 se detecta poco (s√≥lo 17 de 96 casos correctos), muchos son clasificados err√≥neamente como clase 1.
- Esto refleja la dificultad de distinguir la clase minoritaria con los datos y caracter√≠sticas actuales.

---

## Conclusiones y recomendaciones para implementaci√≥n

- El modelo MLP logra un desempe√±o s√≥lido en la clasificaci√≥n general del bienestar psicol√≥gico, especialmente para la clase moderada (clase 1).
- La baja detecci√≥n (recall) de la clase minoritaria (floreciente) sugiere que:
  - Podr√≠a beneficiarse de t√©cnicas espec√≠ficas para balancear clases (sobremuestreo, pesos de clase).
  - M√°s datos o mejores features ayudar√≠an a mejorar la discriminaci√≥n.
- La regularizaci√≥n y arquitectura actual ayudan a evitar overfitting y generan un modelo estable.
- Para aplicaciones pr√°cticas, este modelo puede usarse como filtro inicial para segmentar autom√°ticamente la mayor√≠a de casos en clase moderada.
- Para la clase minoritaria, ser√≠a prudente usar un segundo an√°lisis o evaluaci√≥n complementaria debido al bajo recall.
- Se recomienda validar y ajustar continuamente con datos nuevos y explorar hiperpar√°metros adicionales o t√©cnicas de ensamble para mejorar el desempe√±o global y por clase.

---

## Ajustes y mejoras de optimizaci√≥n del modelo

Perfecto üëç S√≠, tengo todo lo que probaste guardado en esta conversaci√≥n. Podemos organizarlo en una **tabla resumen** para documentar claramente cada escenario de prueba del modelo MLP con SMOTE, incluyendo los par√°metros clave, resultados de accuracy, F1-score y observaciones.

Aqu√≠ te propongo la estructura en **Markdown**:

---

### üìä Resumen Experimentos MLPClassifier + SMOTE

| Escenario            | Capas (hidden\_layer\_sizes) | Iteraciones | Activaci√≥n | Solver | Alpha | SMOTE sampling\_strategy | Accuracy | F1-macro | Recall clase 0 | Recall clase 1 | Recall clase 2 | Observaciones                                                         |
| -------------------- | ---------------------------- | ----------- | ---------- | ------ | ----- | ------------------------ | -------- | -------- | -------------- | -------------- | -------------- | --------------------------------------------------------------------- |
| Original (sin SMOTE) | (30,20)                      | 3000        | logistic   | adam   | 0.01  | Ninguno                  | 0.7404   | 0.57     | 0.58           | 0.87           | 0.18           | Muy buena precisi√≥n global pero clase minoritaria (2) muy baja.       |
| SMOTE + logistic     | (30,20)                      | 3000        | logistic   | adam   | 0.01  | {0:2500, 2:1200}         | 0.6764   | 0.54     | 0.59           | 0.75           | 0.30           | Mejora recall clase 2, pierde algo de accuracy general.               |
| logistic             | (50,30)                      | 3000        | logistic   | adam   | 0.01  | {0:2500, 2:1200}         | 0.6918   | 0.57     | 0.57           | 0.77           | 0.41           | Mejor balance general, especialmente clase 2.                         |
| tanh                 | (50,30)                      | 3000        | tanh       | adam   | 0.01  | {0:2500, 2:1600}         | 0.6329   | 0.51     | 0.54           | 0.70           | 0.32           | Ca√≠da en performance, no recomendado.                                 |
| relu                 | (50,36)                      | 3000        | relu       | sgd    | 0.01  | {0:2500, 2:1600}         | 0.6329   | 0.51     | 0.54           | 0.70           | 0.32           | Similar a tanh, peor recall clase 2.                                  |
| logistic             | (60,30)                      | 3000        | logistic   | sgd    | 0.01  | {0:2500, 2:1200}         | 0.7078   | 0.61     | 0.64           | 0.76           | 0.44           | Mejor performance global, recall clase 2 sube.                        |
| logistic             | (60,40)                      | 3000        | logistic   | adam   | 0.01  | {0:2500, 2:1200}         | 0.6847   | 0.56     | 0.55           | 0.77           | 0.41           | No supera el anterior, menor recall clase 0.                          |
| logistic             | (80,40)                      | 3000        | logistic   | sgd    | 0.01  | {0:2500, 2:1200}         | 0.7078   | 0.61     | 0.64           | 0.76           | 0.46           | Rendimiento muy estable, buena mejora clase minoritaria.              |
| logistic             | (80,40)                      | 2000        | logistic   | sgd    | 0.01  | {0:2500, 2:1200}         | 0.7078   | 0.61     | 0.64           | 0.76           | 0.46           | Igual performance, menos iteraciones = mayor eficiencia.              |
| logistic             | (100,60)                     | 1000        | logistic   | sgd    | 0.01  | {0:2500, 2:1200}         | 0.7078   | 0.61     | 0.64           | 0.76           | 0.46           | Igual performance que anterior, aumenta complejidad innecesariamente. |

Tabla de pruebas realizadas para encontrar soluci√≥n m√°s √≥ptima.

### Conclusiones generales

* **SMOTE** ayuda especialmente a mejorar el recall de la clase minoritaria (clase 2), aunque puede reducir accuracy general.
* **Activaci√≥n logistic + solver sgd + capas (80,40)** ofrece un balance s√≥lido entre recall, precisi√≥n y accuracy.
* **Reducir iteraciones** no impacta negativamente en performance, permitiendo ahorrar tiempo de entrenamiento.
* **Capas muy grandes** o iteraciones excesivas no generan mejoras significativas y pueden causar overfitting.
* Este escenario final **(80,40, logistic, sgd, 2000 iter)** es √≥ptimo para balancear precisi√≥n global y desempe√±o en todas las clases.

---

## Comparativa: Modelo Original vs Modelo √ìptimo con SMOTE

| M√©trica               | Modelo Original | Modelo √ìptimo (SMOTE + MLP) |
| --------------------- | --------------- | --------------------------- |
| **Accuracy**          | 0.7404          | 0.7084                      |
| **Macro F1-score**    | 0.57            | 0.62                        |
| **Recall Clase 0**    | 0.58            | 0.64                        |
| **Recall Clase 1**    | 0.87            | 0.76                        |
| **Recall Clase 2**    | 0.18            | 0.47                        |
| **Precision Clase 0** | 0.66            | 0.61                        |
| **Precision Clase 1** | 0.77            | 0.79                        |
| **Precision Clase 2** | 0.77            | 0.44                        |

---

### Matrices de Confusi√≥n

**Modelo Original:**

```
[[259 191   0]
 [131 882   5]
 [  1  78  17]]
```

**Modelo √ìptimo (SMOTE + MLP):**

```
[[288 162   0]
 [185 775  58]
 [  1  50  45]]
```

---

### An√°lisis de Resultados

1. **Accuracy**

   * El modelo original obtiene mayor accuracy global (0.74 vs 0.71), pero este valor es enga√±oso porque no refleja bien el desempe√±o en la clase minoritaria.

2. **Recall por clase**

   * **Clase 2 (minoritaria)**: mejora dr√°stica con SMOTE (de 0.18 ‚Üí 0.47), lo cual es clave si queremos clasificar bien casos poco frecuentes.
   * **Clase 0** tambi√©n mejora ligeramente (0.58 ‚Üí 0.64).
   * **Clase 1** disminuye un poco (0.87 ‚Üí 0.76), pero sigue alto, mostrando buen balance general.

3. **F1-score macro**

   * Mejora de **0.57 ‚Üí 0.62**, indicando que el modelo √≥ptimo balancea mejor precisi√≥n y recall entre clases.

4. **Precisi√≥n por clase**

   * Clase 2 cae en precisi√≥n (0.77 ‚Üí 0.44), pero ganamos mucho recall, lo que es m√°s importante para detectar correctamente casos minoritarios.

5. **Matrices de Confusi√≥n**

   * El modelo original clasifica muy bien la clase mayoritaria (clase 1) pero casi ignora la clase minoritaria (clase 2: solo 17 aciertos sobre 96).
   * El modelo √≥ptimo mejora considerablemente la detecci√≥n de la clase 2 (45 aciertos sobre 96), sacrificando algo de accuracy general.

## Hallazgos relevantes

* **SMOTE + ajuste de arquitectura MLP** logra un modelo m√°s equilibrado para todas las clases, mejorando especialmente la detecci√≥n de la clase minoritaria, que es cr√≠tico para problemas desbalanceados.
* Aunque la **accuracy total disminuye ligeramente**, la ganancia en recall y F1-score macro justifica la mejora, ya que el modelo no prioriza √∫nicamente la clase mayoritaria.
* El nuevo modelo es una opci√≥n √≥ptima para implementaci√≥n, especialmente considerando el **minimizar falsos negativos en la clase minoritaria**.
