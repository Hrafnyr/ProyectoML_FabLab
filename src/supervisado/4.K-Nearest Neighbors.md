
### Propósito

El propósito de este experimento es aplicar el algoritmo supervisado **K-Nearest Neighbors (KNN)** para clasificar los datos del dataset `4datasetListo.csv`, prediciendo la variable objetivo `mhc_dx`, que representa un diagnóstico de salud mental categórico. Se busca evaluar el rendimiento del modelo con métricas de clasificación y analizar su capacidad para distinguir entre las distintas clases.

---

### Puntos Clave del Modelo

| Etapa                            | Descripción                                                                                    |
| -------------------------------- | ---------------------------------------------------------------------------------------------- |
| **Tipo de modelo**               | Supervisado, clasificación                                                                     |
| **Algoritmo**                    | K-Nearest Neighbors (KNN)                                                                      |
| **Hiperparámetros usados**       | `n_neighbors=7`, `weights='distance'`                                                          |
| **Tamaño de test**               | 20% del dataset                                                                                |
| **Normalización**                | `StandardScaler` para escalar las features                                                     |
| **Features utilizadas**          | 18 características relevantes, incluyendo salud mental, afectividad, edad, género, entre otras |
| **Variable objetivo (`target`)** | `mhc_dx` (etiquetas 0, 1, 2)                                                                   |
| **Evaluación**                   | Accuracy, classification report, matriz de confusión                                           |

---

### Análisis de Resultados

#### Accuracy global

```text
Accuracy: 0.8363
```

---

#### Classification Report

```text
              precision    recall  f1-score   support

           0       0.81      0.79      0.80       450
           1       0.85      0.91      0.88      1018
           2       0.79      0.24      0.37        96

    accuracy                           0.84      1564
   macro avg       0.82      0.65      0.68      1564
weighted avg       0.83      0.84      0.83      1564
```

---

#### Matriz de Confusión

```
[[356  94   0]
 [ 83 929   6]
 [  0  73  23]]
```

---

###  Interpretación y Conclusiones

* **Clase 1 (etiqueta 1)** es la mejor clasificada: alto recall (0.91) y f1-score (0.88).
* **Clase 0** tiene buen desempeño general, aunque algunas instancias se confunden con clase 1.
* **Clase 2** es la más problemática:

  * Solo 23 de 96 casos se clasificaron correctamente.
  * El modelo tiende a confundir esta clase con la clase 1.
  * El bajo recall (0.24) indica que **no logra recuperar bien los verdaderos positivos** de esta clase.

---

### Posibles causas del bajo rendimiento en clase 2

* Poca representación en el dataset (desbalance de clases).
* Alta similitud con clase 1 en el espacio de características.
* KNN no aprende patrones complejos ni tiene capacidad de generalización cuando los datos están desbalanceados o mal distribuidos.

---
